{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 0.1.1. Feature selection\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load dataset\n",
    "TARGET_VARIABLE = 'price'\n",
    "california_housing = pd.DataFrame(np.column_stack((fetch_california_housing().data, fetch_california_housing().target)),\n",
    "        columns = np.append(fetch_california_housing().feature_names, TARGET_VARIABLE))\n",
    "california_housing = california_housing.sample(n=1000, random_state=42)  # sampling from 20640 to 1000\n",
    "y = california_housing[TARGET_VARIABLE].values  # Target variable\n",
    "X_all = california_housing[fetch_california_housing().feature_names].values  # Feature values\n",
    "# Feature selection by RFE\n",
    "selector = RFE(RandomForestRegressor(random_state=42), n_features_to_select=5)\n",
    "selector.fit(X_all, y)\n",
    "print(fetch_california_housing().feature_names)\n",
    "print(selector.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 0.1.2. Load dataset with selected explanatory variables\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "TARGET_VARIABLE = 'price'  # Target variable name\n",
    "USE_EXPLANATORY = ['MedInc', 'AveOccup', 'Latitude', 'HouseAge']  # Selected explanatory variables\n",
    "california_housing = pd.DataFrame(np.column_stack((fetch_california_housing().data, fetch_california_housing().target)),\n",
    "        columns = np.append(fetch_california_housing().feature_names, TARGET_VARIABLE))\n",
    "california_housing = california_housing.sample(n=1000, random_state=42)  # sampling from 20640 to 1000\n",
    "y = california_housing[TARGET_VARIABLE].values  # Target variable\n",
    "X = california_housing[USE_EXPLANATORY].values  # Explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 0.2. Initialize tuning class\n",
    "import parent_import\n",
    "from tune_easy import LGBMRegressorTuning\n",
    "tuning = LGBMRegressorTuning(X,  # Explanatory variables(numpy.ndarray)\n",
    "                             y,  # Target variables(numpy.ndarray)\n",
    "                             USE_EXPLANATORY,  # Column names of explanatory variables\n",
    "                             eval_set_selection='test'  # How to determine `eval_set`\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 1. Select validation score\n",
    "SCORING = 'neg_root_mean_squared_error'  # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 2. Select parameter range using validation curve\n",
    "from sklearn.model_selection import KFold\n",
    "# Parameter range for validation curve\n",
    "VALIDATION_CURVE_PARAMS = {'reg_alpha': [0, 0.0001, 0.001, 0.003, 0.01, 0.03, 0.1, 1, 10],\n",
    "                           'reg_lambda': [0, 0.0001, 0.001, 0.003, 0.01, 0.03, 0.1, 1, 10],\n",
    "                           'num_leaves': [2, 4, 8, 16, 32, 64, 96, 128, 192, 256],\n",
    "                           'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                           'subsample': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                           'subsample_freq': [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "                           'min_child_samples': [0, 2, 5, 10, 20, 30, 50, 70, 100]\n",
    "                           }\n",
    "# Plot validation curve\n",
    "tuning.plot_first_validation_curve(validation_curve_params=VALIDATION_CURVE_PARAMS,\n",
    "                                   scoring=SCORING,\n",
    "                                   cv=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4.1 Select cross validation instance\n",
    "CV = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4.2.1 Calculate validation score before tuning\n",
    "from lightgbm import LGBMRegressor\n",
    "from seaborn_analyzer import cross_val_score_eval_set\n",
    "import numpy as np\n",
    "# Fit parameters passed to estimator.fit()\n",
    "FIT_PARAMS = {'verbose': 0,\n",
    "              'early_stopping_rounds': 10,\n",
    "              'eval_metric': 'rmse',\n",
    "              'eval_set': [(X, y)]\n",
    "              }\n",
    "# Parameters not used in optimization\n",
    "NOT_OPT_PARAMS = {'objective': 'regression',\n",
    "                  'random_state': 42,\n",
    "                  'boosting_type': 'gbdt',\n",
    "                  'n_estimators': 10000\n",
    "                  }\n",
    "# Make estimator instance\n",
    "lgbmr = LGBMRegressor(**NOT_OPT_PARAMS)\n",
    "# Calculate validation score\n",
    "scores = cross_val_score_eval_set('test',  # How to choose \"eval_set\" data\n",
    "        lgbmr, X, y,  # Input data\n",
    "        scoring=SCORING,  # Validation score selected in section 1\n",
    "        cv=CV,  # Cross validation instance selected in section 4.1\n",
    "        fit_params=FIT_PARAMS  # Fit parameters passed to estimator.fit()\n",
    "        )\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4.2.2 Visualize estimator before tuning\n",
    "from seaborn_analyzer import regplot\n",
    "california_housing['price'] = y\n",
    "regplot.regression_pred_true(lgbmr,\n",
    "                             x=tuning.x_colnames,\n",
    "                             y='price',\n",
    "                             data=california_housing,\n",
    "                             scores='rmse',\n",
    "                             cv=CV,\n",
    "                             fit_params=FIT_PARAMS,\n",
    "                             eval_set_selection='test'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 4.3 Execute parameter tuning\n",
    "# Select parameter range of optuna\n",
    "TUNING_PARAMS = {'reg_alpha': (0.0001, 0.1),\n",
    "                 'reg_lambda': (0.0001, 0.1),\n",
    "                 'num_leaves': (2, 50),\n",
    "                 'colsample_bytree': (0.4, 1.0),\n",
    "                 'subsample': (0.4, 1.0),\n",
    "                 'subsample_freq': (0, 7),\n",
    "                 'min_child_samples': (0, 50)\n",
    "                 }\n",
    "# Execute parameter tuning\n",
    "best_params, best_score = tuning.optuna_tuning(scoring=SCORING,\n",
    "                                               tuning_params=TUNING_PARAMS,\n",
    "                                               cv=CV,\n",
    "                                               not_opt_params=NOT_OPT_PARAMS,\n",
    "                                               fit_params=FIT_PARAMS\n",
    "                                               )\n",
    "print(f'Best parameters\\n{best_params}\\n')  # Optimized parameters\n",
    "print(f'Not tuned parameters\\n{tuning.not_opt_params}\\n')  # Parameters not used in optimization\n",
    "print(f'Best score\\n{best_score}\\n')  # Best score in optimized parameters\n",
    "print(f'Elapsed time\\n{tuning.elapsed_time}\\n')  # Elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5.1 Plot score increase history\n",
    "tuning.plot_search_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5.2 Visualize relationship between parameters and validation score\n",
    "tuning.plot_search_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5.3 Plot learning curve\n",
    "tuning.plot_best_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 5.4 Plot validation curve\n",
    "tuning.plot_best_validation_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 6.1 Retain optimized estimator\n",
    "from seaborn_analyzer import cross_val_score_eval_set\n",
    "params_after = {}\n",
    "params_after.update(tuning.best_params)\n",
    "params_after.update(tuning.not_opt_params)\n",
    "best_estimator = LGBMRegressor(**params_after)\n",
    "# Calculate validation score\n",
    "scores = cross_val_score_eval_set('test',  # How to choose \"eval_set\" data\n",
    "        best_estimator, X, y,\n",
    "        scoring=tuning.scoring,  # Validation score selected in section 1\n",
    "        cv=tuning.cv,  # Cross validation instance selected in section 4.2\n",
    "        fit_params=tuning.fit_params  # Fit parameters passed to estimator.fit()\n",
    "        )\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% 6.2 Visualize estimator after tuning\n",
    "from seaborn_analyzer import regplot\n",
    "regplot.regression_pred_true(best_estimator,\n",
    "                             x=tuning.x_colnames,\n",
    "                             y='price',\n",
    "                             data=california_housing,\n",
    "                             scores='rmse',\n",
    "                             cv=tuning.cv,\n",
    "                             fit_params=tuning.fit_params,\n",
    "                             eval_set_selection='test'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6f89127ceee22c9cf40cfee970a61db645cf2c046ea3ef2bb5f3b1cfb3d50ef"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
